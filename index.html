<!DOCTYPE html>
<html>
<head>
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0" charset='utf-8'.> -->
  <meta charset='utf8'>
  <style >.hogehoge {
    padding: 20px;
    margin: 20px;
  }
  /* .wrapper{
  width: 100%;
  height: 100%;
} */
  </style>
  <script async src="opencv.js" type="text/javascript" onload="OpenCvReady();"></script>
  <!-- <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript" onload="OpenCvReady();"></script> -->
</head>
<body>
  
  <div class="camera">
    <video id="video" autoplay playsinline></video>
</div><br>
<canvas id="movie" ></canvas>
<canvas id="canvas"></canvas>

<img id="inputImage" src="keybordinv.png" style="display: none;">

<p id="text"></p>

<button class="hogehoge" type="button" id="start">start</button>
<!-- <button class="hogehoge" type="button" id="stop">next</button> -->
<!-- <botton type="button" id="download">dl</botton> -->

<script>

  const startbutton = document.getElementById('start');
  // const nextbutton  = document.getElementById('stop');
  // var downloadbutton = document.getElementById('download');

  const video = document.getElementById('video');// 適当にvideoタグのオブジェクトを取得

  var constrains = { 
    // video: {facingMode:{   "user"
    video: {facingMode:   "environment"
    }
  }
  var curSTREAM = null;

  const movie = document.getElementById("movie");
  const canvas = document.getElementById("canvas");

  const ctx = movie.getContext("2d");
  const cty = canvas.getContext("2d");

  let imgElement = document.getElementById("inputImage");

  const text = document.getElementById("text");

  let flagstart = false;
  let flagpoint = false;
  let selectbord = 0;
  let keybordpoint = [];

  let startdata = null;
  let startkeypoints = null;
  let startdescriptors = null;

  function drawCameraToCanvas() {

    if(selectbord){
      // 現在のフレームを<canvas>に描画
      cty.drawImage(video, 0, 0, video.width, video.height, 0, 0, canvas.width, canvas.height);
      let srcresult = cv.imread(canvas);

      ctx.drawImage(video, 0, 0, video.width, video.height, 0, 0, movie.width, movie.height);
      let src = cv.imread(movie);

      let gray = new cv.Mat();
      // グレースケールに変換（特徴点検出に適した前処理）
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

      let equalized = new cv.Mat();
      // ヒストグラム均等化（コントラストをハッキリさせる）
      cv.equalizeHist(gray, equalized);

      // ORB検出器を作成
      const orb = new cv.ORB();
      let keypoints = new cv.KeyPointVector();
      let descriptors = new cv.Mat();

      // // 特徴点を検出
      orb.detectAndCompute(equalized, new cv.Mat(), keypoints, descriptors);

      console.log("特徴点抽出：" + keypoints.size());

      if (startdata === null) {
        startdata = equalized.clone();
        startkeypoints = keypoints.clone();
        startdescriptors = descriptors.clone();
        flagpoint = false;
      } else{
        // KNNマッチング
        const bf = new cv.BFMatcher(cv.NORM_HAMMING, false); // クロスチェックを無効に設定
        const knnMatches = new cv.DMatchVectorVector();
        bf.knnMatch(startdescriptors, descriptors, knnMatches, 2); // k=2

        // Loweの比率テスト
        let leng = 0;
        const goodMatches = new cv.DMatchVector();
        let pts1 = [];
        let pts2 = [];
        for (let i = 0; i < knnMatches.size(); i++) {
          const m = knnMatches.get(i).get(0); // 最良のマッチ
          const n = knnMatches.get(i).get(1); // 次点のマッチ
          if (m.distance < 0.75 * n.distance) { // 比率テスト: 0.75が一般的
            goodMatches.push_back(m);
            pts1.push(startkeypoints.get(m.queryIdx).pt);
            pts2.push(keypoints.get(m.trainIdx).pt);
          }
        }

        console.log(pts1.length);
        leng = pts1.length;

        let p1 = [];
        let p2 = [];
        for(i=0; i< leng ;i++){
          let a = [];
          let b = [];
          a.push(pts1[i].x);
          a.push(pts1[i].y);
          b.push(pts2[i].x);
          b.push(pts2[i].y);
          p1.push(a);
          p2.push(b);
        }
        
        let matrix = [];
        let count = 0;
        if(leng > 4){
          const srcPoints = cv.matFromArray(p1.length, 1, cv.CV_32FC2, p1.flat());
          const dstPoints = cv.matFromArray(p2.length, 1, cv.CV_32FC2, p2.flat());
          const mask = new cv.Mat();
          const homography = cv.findHomography(srcPoints, dstPoints, cv.RANSAC, 5, mask);

          for (let i = 0; i < homography.rows; i++) {
            let row = [];
            for (let j = 0; j < homography.cols; j++) {
              row.push(homography.doubleAt(i, j)); // doubleAtで値を取得
            }
            matrix.push(row);
          }
          // console.log(homography.rows);
          console.log(matrix);

          // マスクを適用して正しいマッチを数える
          
          // const inlierMatches = new cv.DMatchVector();
          for (let i = 0; i < mask.rows; i++) {
            if (mask.data[i]) {
              count++;
              // inlierMatches.push_back(goodMatches.get(i));
            }
          }
          text.textContent = count;

          srcPoints.delete();
          dstPoints.delete();
          mask.delete();
          homography.delete();
        }

        let flagp = 0;
        if(flagpoint){
          flagp = 1;
          flagpoint = false;

          startdata.delete();
          startkeypoints.delete();
          startdescriptors.delete();

          startdata = equalized.clone();
          startkeypoints = keypoints.clone();
          startdescriptors = descriptors.clone();
        }

        if(count > 10){
          //ずれを修正
          let setpoint = [];
          for(i=0; i < (selectbord - flagp) ;i++){
            let xy1 = [];
            let sp = [];
            for(j=0;j<3;j++){
              const sum = matrix[j][0] * keybordpoint[i][0] * movie.width / canvas.width + matrix[j][1] * keybordpoint[i][1] *movie.height /canvas.height + matrix[j][2];
              xy1.push(sum);
            }
            if(flagp){
              keybordpoint[i][0] = xy1[0] * canvas.width / movie.width / xy1[2];
              keybordpoint[i][1] = xy1[1] *canvas.height /movie.height / xy1[2];
            }
            sp.push(xy1[0] * canvas.width / movie.width / xy1[2]);
            sp.push(xy1[1] *canvas.height /movie.height / xy1[2]);
            setpoint.push(sp);
          }
          
          if(selectbord < 4){
            const color = new cv.Scalar(255, 0, 0, 255);

            for(i=0; i < (selectbord - flagp) ;i++){
              cv.circle(srcresult, {x: setpoint[i][0], y: setpoint[i][1]}, 5, color, 2);
            }
          }else{
            if(flagp){
              //バブルソート
              for(j=3;j>0;j--){
                if((keybordpoint[j-1][0] + keybordpoint[j-1][1]) > (keybordpoint[j][0] + keybordpoint[j][1])){
                  let temp = keybordpoint[j];
                  keybordpoint[j] = keybordpoint[j-1];
                  keybordpoint[j-1] = temp;
                }
              }
              for(j=1;j<3;j++){
                if((keybordpoint[j+1][0] + keybordpoint[j+1][1]) < (keybordpoint[j][0] + keybordpoint[j][1])){
                  let temp = keybordpoint[j];
                  keybordpoint[j] = keybordpoint[j+1];
                  keybordpoint[j+1] = temp;
                }
              }
              if(keybordpoint[1][1] > keybordpoint[2][1]){
                let temp = keybordpoint[1];
                keybordpoint[1] = keybordpoint[2];
                keybordpoint[2] = temp;
              }
              let temp1 = keybordpoint[3];
                keybordpoint[3] = keybordpoint[2];
                keybordpoint[2] = temp1;
            }else{
              console.log("key");
              let img = cv.imread(imgElement);
              const kbinv = [[0, 0], [img.cols, 0], [img.cols, img.rows], [0, img.rows]];
              const srcPoints = cv.matFromArray(4, 1, cv.CV_32FC2, kbinv.flat());
              const dstPoints = cv.matFromArray(4, 1, cv.CV_32FC2, setpoint.flat());

              const homography = cv.findHomography(srcPoints, dstPoints);
              //ホモグラフィ行列を計算

              console.log(homography);
              //画像Aを変形
              let warped = new cv.Mat();
              let size = new cv.Size(srcresult.cols, srcresult.rows);
              cv.warpPerspective(img, warped, homography, size);

              console.log("change2");
              //画像Bに合成（透過部分を利用）
              let mask = new cv.Mat();
              cv.threshold(warped, mask, 1, 255, cv.THRESH_BINARY);
              let invMask = new cv.Mat();
              cv.bitwise_not(mask, invMask);

              console.log("change3");
              let bg = new cv.Mat();
              let fg = new cv.Mat();
              // cv.bitwise_and(srcresult, srcresult, bg, invMask);
              cv.bitwise_and(srcresult, invMask, bg);
              console.log("change4");
              // cv.bitwise_and(warped, warped, fg, mask);
              cv.bitwise_and(warped, mask, fg);

              cv.add(bg, fg, srcresult);

              //メモリ解放
              img.delete();
              srcPoints.delete();
              dstPoints.delete();
              homography.delete();
              warped.delete();
              mask.delete();
              invMask.delete();
              bg.delete();
              fg.delete();
              
              // console.log(keybordpoint);

              // const color = new cv.Scalar(255, 0, 0, 100);

              // for(i=0;i<4;i++){
              // cv.line(srcresult, {x: setpoint[i][0], y: setpoint[i][1]}, 
              //                   {x: setpoint[(i + 1)% 4][0], y: setpoint[(i + 1)% 4][1]}, color, 2);
              // }
            }
          }
        }
        // console.log("x")
        cv.imshow('canvas', srcresult);

        bf.delete();
        knnMatches.delete();
        goodMatches.delete();
        
        // inlierMatches.delete();
      }

      // メモリの解放
      src.delete();
      gray.delete();
      equalized.delete();
      keypoints.delete();
      descriptors.delete();
      orb.delete();
      srcresult.delete();

    }else{
      cty.drawImage(video, 0, 0, video.width, video.height, 0, 0, canvas.width, canvas.height);
    }

    // 再度次のフレームを描画するためにrequestAnimationFrameを使う
    requestAnimationFrame(drawCameraToCanvas);
  }

  canvas.addEventListener('click', event =>{
    if(flagstart){
      const rect = canvas.getBoundingClientRect();
      let kbp = [];

      kbp.push((event.clientX - rect.left) * canvas.width / canvas.clientWidth);
      kbp.push((event.clientY - rect.top) * canvas.height /canvas.clientHeight);
      keybordpoint.push(kbp);

      selectbord++;
      flagpoint = true;

      if(selectbord >= 4){
        flagstart = false;
      }
    }
  });

  function vkeybord() {
    console.log("バーチャルキーボード開始");

    console.log(constrains);
    navigator.mediaDevices.getUserMedia(constrains)
    .then(function (stream) {
      curSTREAM = stream;
      video.srcObject = stream; // streamはユーザーのカメラとマイクの情報で、これをvideoの入力ソースにする
      video.play();

      const videoTrack = stream.getVideoTracks()[0];
      // ビデオトラックの設定を取得
      const settings = videoTrack.getSettings();
      // カメラの解像度を取得
      video.width  = settings.width;
      video.height = settings.height;
      console.log(video.height);

      // movie.width = movie.height *video.width /video.height
      canvas.height = canvas.width * video.height / video.width;
      
      movie.width = 400;
      movie.height = movie.width *video.height /video.width;

      // text.textContent = canvas.width + ":" + canvas.height;

      // 映像の準備ができたら描画開始
      video.onplaying = () => {
        drawCameraToCanvas();
      };

      console.log("dl");
    })
    .catch(function(err) {
        console.log("An error occured! " + err);
    })
  }

  function OpenCvReady(){
    console.log("OpenCVが読み込み完了");

    // cv.onRuntimeInitialized = vkeybord;
  }

  window.addEventListener('load' , function(){
    console.log("初期読み込み完了");
    console.log(cv);
    console.log(typeof (cv.imread));

    canvas.width  = window.innerWidth;
    canvas.height = window.innerHeight;
    console.log(video.height);
    
    video.style = 'display:none';
    video.muted = 'true';
    movie.style = 'display:none';

    startbutton.addEventListener('click', function(){
      flagstart = true;
    });
    vkeybord();
  })

</script>
</body>
</html>