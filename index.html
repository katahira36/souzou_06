<!DOCTYPE html>
<html>
<head>
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0" charset='utf-8'.> -->
  <meta charset='utf8'>
  <!-- <style >.hogehoge {
    padding: 20px;
    margin: 20px;
  }
  /* .wrapper{
  width: 100%;
  height: 100%;
} */
  </style> -->
  <script async src="opencv.js" type="text/javascript" onload="OpenCvReady();"></script>
  <!-- <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript" onload="OpenCvReady();"></script> -->
</head>
<body>
  
  <div class="camera">
    <video id="video" autoplay playsinline></video>
</div><br>
<canvas id="movie" ></canvas>
<canvas id="canvas"></canvas>

<p id="text"></p>

<button class="hogehoge" type="button" id="start">start</button>
<button class="hogehoge" type="button" id="stop">next</button>
<!-- <botton type="button" id="download">dl</botton> -->

<script>

  const startbutton = document.getElementById('start');
  const nextbutton  = document.getElementById('stop');
  // var downloadbutton = document.getElementById('download');

  const video = document.getElementById('video');// 適当にvideoタグのオブジェクトを取得

  var constrains = { 
    // video: {facingMode:{   "user"
    video: {facingMode:   "environment"
    }
  }
  var curSTREAM = null;

  const movie = document.getElementById("movie");
  const canvas = document.getElementById("canvas");

  const ctx = movie.getContext("2d");
  const cty = canvas.getContext("2d");

  const text = document.getElementById("text");

  let startdata = null;
  let startkeypoints = null;
  let startdescriptors = null;
  var incri = 0;
  var leng = 0;
  let match = null;
  let pts1 = [];
  let pts2 = [];
  let matrix = [];

  function drawCameraToCanvas() {

    // 現在のフレームを<canvas>に描画
    movie.width = canvas.width/2;
    ctx.drawImage(video, 0, 0, video.width, video.height, 0, 0, movie.width, movie.height);
    let src = cv.imread(movie);

    // cty.drawImage(video, 0, 0, video.width, video.height, 0, 0, canvas.width, canvas.height);
    // let cav = cv.imread(movie);

    let gray = new cv.Mat();
    // グレースケールに変換（特徴点検出に適した前処理）
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    let equalized = new cv.Mat();
    // ヒストグラム均等化（コントラストをハッキリさせる）
    cv.equalizeHist(gray, equalized);

    // ORB検出器を作成
    const orb = new cv.ORB();
    let keypoints = new cv.KeyPointVector();
    let descriptors = new cv.Mat();

    // // 特徴点を検出
    orb.detectAndCompute(equalized, new cv.Mat(), keypoints, descriptors);

    if (startdata === null) {
      startdata = equalized.clone();
      startkeypoints = keypoints.clone();
      startdescriptors = descriptors.clone();
    } else{
      // KNNマッチング
      const bf = new cv.BFMatcher(cv.NORM_HAMMING, false); // クロスチェックを無効に設定
      const knnMatches = new cv.DMatchVectorVector();
      bf.knnMatch(startdescriptors, descriptors, knnMatches, 2); // k=2

      // Loweの比率テスト
      leng = 0;
      const goodMatches = new cv.DMatchVector();
      pts1 = [];
      pts2 = [];
      for (let i = 0; i < knnMatches.size(); i++) {
        const m = knnMatches.get(i).get(0); // 最良のマッチ
        const n = knnMatches.get(i).get(1); // 次点のマッチ
        if (m.distance < 0.75 * n.distance) { // 比率テスト: 0.75が一般的
          goodMatches.push_back(m);
          pts1.push(startkeypoints.get(m.queryIdx).pt);
          pts2.push(keypoints.get(m.trainIdx).pt);
        }
      }

      console.log(pts1.length);
      leng = pts1.length;
      
      matrix = [];
      
      const srcPoints = cv.matFromArray(pts1.length, 1, cv.CV_32FC2, pts1.flat());
      const dstPoints = cv.matFromArray(pts2.length, 1, cv.CV_32FC2, pts2.flat());
      const mask = new cv.Mat();
      const homography = cv.findHomography(srcPoints, dstPoints, cv.RANSAC, 10000, mask);

      for (let i = 0; i < homography.rows; i++) {
        let row = [];
        for (let j = 0; j < homography.cols; j++) {
          row.push(homography.doubleAt(i, j)); // doubleAtで値を取得
        }
        matrix.push(row);
      }
      console.log(homography.rows);
      console.log(matrix);
      // // マスクを適用して正しいマッチだけ描画
      // const inlierMatches = new cv.DMatchVector();
      // for (let i = 0; i < mask.rows; i++) {
      //   if (mask.data[i]) {
      //     inlierMatches.push_back(goodMatches.get(i));
      //   }
      // }

      const result = new cv.Mat();
      // cv.hconcat([startdata, equalized], result);
      cv.drawMatches(startdata, startkeypoints, equalized, keypoints, goodMatches, result, [0, 255, 0, 255]);
      if(!(match === null)){
        match.delete();
      }
      match = result.clone();

      incri = 0;

      // const result = new cv.Mat();
      // cv.drawMatches(startdata, startkeypoints, equalized, keypoints, inlierMatches, result, [0, 255, 0, 255]);
      // cv.drawMatches(startdata, startkeypoints, equalized, keypoints, goodMatches, result, [0, 255, 0, 255]);

      // cv.imshow('movie', result);

      bf.delete();
      knnMatches.delete();
      goodMatches.delete();
      srcPoints.delete();
      dstPoints.delete();
      mask.delete();
      homography.delete();
      result.delete();
      // inlierMatches.delete();
      // result.delete();

    }

    // 結果をCanvasに描画
    cty.drawImage(movie, 0, 0, movie.width, movie.height, 0, 0, canvas.width, canvas.height);

    // メモリの解放
    src.delete();
    gray.delete();
    equalized.delete();
    keypoints.delete();
    descriptors.delete();
    orb.delete();

    // 再度次のフレームを描画するためにrequestAnimationFrameを使う
    // requestAnimationFrame(drawCameraToCanvas);
  }

  nextbutton.addEventListener('click', function(){
    let pt1 = [];
    let pt2 = [];

    // let pt1 = [[0,0],[3,0],[0,2],[3,2]];
    // let pt2 = [[1,0],[4,0],[1,2],[4,2]];

    console.log(incri);
    console.log(leng);

    let work = match.clone();
    // cv.imshow('movie', match);

    console.log("b");
    const offset = startdata.cols;
    const color = new cv.Scalar(255, 0, 0, 255);
    for(let i = 0;i < 4;i++){
      const a = (incri * 4 + i) % leng;

      cv.circle(work, pts1[a], 5, color, 2);
      cv.circle(work, { x: pts2[a].x + offset, y: pts2[a].y }, 5, color, 2);
      cv.line(work, pts1[a], { x: pts2[a].x + offset, y: pts2[a].y }, color, 1);

      pt1.push({ x: Math.round(pts1[a].x), y: Math.round(pts1[a].y) });
      pt2.push({ x: Math.round(pts2[a].x), y: Math.round(pts2[a].y) });
    }

    console.log(pt2);
    let flag = true;
    let tmatrix = [];
    let point = [];
    for(let i1=0;(i1<3) && flag; i1++){
      for(let i2=0;(i2<3) && flag; i2++){
        for(let i3=0;(i3<3) && flag; i3++){
          for(let i4=0;(i4<3) && flag; i4++){
            for(let i5=0;(i5<3) && flag; i5++){
              for(let i6=0;(i6<3) && flag; i6++){
                for(let i7=0;(i7<3) && flag; i7++){
                  for(let i8=0;(i8<3) && flag; i8++){
                    point[0] = { x: pt1[0].x + ((((i1 + 1) / 2)|0) * ((i1 & 1)? 1:-1)), y: pt1[0].y +((((i5 + 1) / 2)|0) * ((i5 & 1)? 1:-1))}
                    point[1] = { x: pt1[1].x + ((((i2 + 1) / 2)|0) * ((i2 & 1)? 1:-1)), y: pt1[1].y +((((i6 + 1) / 2)|0) * ((i6 & 1)? 1:-1))}
                    point[2] = { x: pt1[2].x + ((((i3 + 1) / 2)|0) * ((i3 & 1)? 1:-1)), y: pt1[2].y +((((i7 + 1) / 2)|0) * ((i7 & 1)? 1:-1))}
                    point[3] = { x: pt1[3].x + ((((i4 + 1) / 2)|0) * ((i4 & 1)? 1:-1)), y: pt1[3].y +((((i8 + 1) / 2)|0) * ((i8 & 1)? 1:-1))}

                    const srcPoints = cv.matFromArray(point.length, 1, cv.CV_32FC2, point.flat());
                    const dstPoints = cv.matFromArray(pt2.length, 1, cv.CV_32FC2, pt2.flat());
                    const mask = new cv.Mat();
                    const homography = cv.findHomography(srcPoints, dstPoints, cv.RANSAC, 10000, mask);
                    
                    console.log(point);
                    console.log(pt1[3].y);
                    console.log(pt1[3].y+((((i8 + 1) / 2)|0) * ((i8 & 1)? 1:-1)));
                    console.log(((((i8 + 1) / 2)|0) * ((i8 & 1)? 1:-1)));
                    console.log((((i8 + 1) / 2)|0));
                    console.log((((i8 & 1)? 1:-1)));

                    if(homography.doubleAt(0,0)){
                      flag = false;
                      for (let i = 0; i < homography.rows; i++) {
                        let row = [];
                        for (let j = 0; j < homography.cols; j++) {
                          row.push(homography.doubleAt(i, j)); // doubleAtで値を取得
                        }
                        tmatrix.push(row);
                      }
                    }
                    
                    srcPoints.delete();
                    dstPoints.delete();
                    mask.delete();
                    homography.delete();
                  }
                }
              }
            }
          }
        }
      }
    }
    console.log(point);
    console.log(pt2);
    console.log(tmatrix);

    console.log("c");
    cv.imshow('movie', work);
    cty.drawImage(movie, 0, 0, movie.width, movie.height, 0, 0, canvas.width, canvas.height);

    text.textContent = (incri * 4 + 4) + "/" + (leng + 1);

    incri = (incri + 1) % ((leng - 1) / 4 + 1);
  });

  function vkeybord() {
    console.log("バーチャルキーボード開始");

    console.log(constrains);
    navigator.mediaDevices.getUserMedia(constrains)
    .then(function (stream) {
      curSTREAM = stream;
      video.srcObject = stream; // streamはユーザーのカメラとマイクの情報で、これをvideoの入力ソースにする
      video.play();

      const videoTrack = stream.getVideoTracks()[0];
      // ビデオトラックの設定を取得
      const settings = videoTrack.getSettings();
      // カメラの解像度を取得
      video.width  = settings.width;
      video.height = settings.height;
      console.log(video.height);

      // movie.width = movie.height *video.width /video.height
      canvas.height = canvas.width * video.height / video.width;
      canvas.width = canvas.width *2;
      
      movie.width = 400;
      movie.height = movie.width *video.height /video.width;

      // text.textContent = canvas.width + ":" + canvas.height;

      // 映像の準備ができたら描画開始
      video.onplaying = () => {
        drawCameraToCanvas();
      };

      console.log("dl");
    })
    .catch(function(err) {
        console.log("An error occured! " + err);
    })
  }

  function OpenCvReady(){
    console.log("OpenCVが読み込み完了");

    // cv.onRuntimeInitialized = vkeybord;
  }

  window.addEventListener('load' , function(){
    console.log("初期読み込み完了");
    console.log(cv);
    console.log(typeof (cv.imread));

    canvas.width  = window.innerWidth;
    canvas.height = window.innerHeight;
    console.log(video.height);
    
    video.style = 'display:none';
    video.muted = 'true';
    movie.style = 'display:none';

    startbutton.addEventListener('click', drawCameraToCanvas);
    vkeybord();
  })

</script>
</body>
</html>